{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd72e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Author: Ishita Jalan ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b53972",
   "metadata": {},
   "source": [
    "## Step 1: Converting netcdf to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca23b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert netcdf files to csv (matrix format)\n",
    "\n",
    "def GLEAMtocsv(dataset,year,dataname):\n",
    "    os.chdir('D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\AET_csv')\n",
    "    latbounds = [6.125,12.500]\n",
    "    lonbounds = [0.675, 4.300]\n",
    "    \n",
    "    ds = nc.Dataset(dataset)\n",
    "    \n",
    "    lat = ds.variables['lat'][:] \n",
    "    lon = ds.variables['lon'][:]\n",
    "    aet = ds.variables['E']\n",
    "    time = ds.variables['time'][:]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "    \n",
    "    startdate = \"01-01-\"+str(year)\n",
    "    \n",
    "    day_counter = 0\n",
    "    \n",
    "    for day in range(len(time)):\n",
    "        enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=day_counter)\n",
    "        print (\"Days Processed\", day_counter+1)\n",
    "        \n",
    "        TempSubset = ds.variables['E'][day, lonli:lonui, latui:latli]\n",
    "        temp = np.matrix(TempSubset)\n",
    "        \n",
    "        df = pd.DataFrame(data=temp, columns=(lat[latui:latli]), index=(lon[lonli:lonui]))\n",
    "        day_counter = day_counter+1\n",
    "  \n",
    "        # end date timesstamp to string     \n",
    "        file_date_refined = enddate.strftime('%Y-%m-%d')\n",
    "        df.to_csv(file_date_refined + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function\n",
    "\n",
    "GLEAMtocsv(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\E_2005_GLEAM_v35b.nc',2005,'ET_2005')\n",
    "GLEAMtocsv(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\E_2006_GLEAM_v35b.nc',2006,'ET_2006')\n",
    "GLEAMtocsv(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\E_2007_GLEAM_v35b.nc',2007,'ET_2007')\n",
    "GLEAMtocsv(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\E_2008_GLEAM_v35b.nc',2008,'ET_2008')\n",
    "GLEAMtocsv(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\E_2009_GLEAM_v35b.nc',2009,'ET_2009')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7410c",
   "metadata": {},
   "source": [
    "## Step 2: Compiling into time-seriesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7035f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling daily csv to time series\n",
    "\n",
    "# Creating a main dataframe to store data from other csv files\n",
    "def compileAET(filename,directory):\n",
    "    \n",
    "    os.chdir(directory)\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    row, col = df.shape\n",
    "    time_series = pd.DataFrame()\n",
    "    ls =[]\n",
    "\n",
    "    for r in range(row):\n",
    "        for c in range(col-1):\n",
    "            x = df.iloc[r,0]\n",
    "            y = df.columns.values[c+1]\n",
    "            col_head = str(y)+\",\"+str(x) #defining the column name using the lat,long\n",
    "            time_series[col_head] = df.iloc[r,c+1]\n",
    "\n",
    "    time_series.to_csv(\"main.csv\")\n",
    "\n",
    "    #Processing data from other csv files to the main csv file\n",
    "    i=0\n",
    "\n",
    "    for year in range(2005,2010):\n",
    "    \n",
    "        filepath = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\E_' + str(year) + '_GLEAM_v35b.nc'\n",
    "        ds = nc.Dataset(filepath)\n",
    "    \n",
    "        time = ds.variables['time'][:]\n",
    "    \n",
    "        startdate = \"01-01-\"+str(year)\n",
    "        day_counter = 0\n",
    "    \n",
    "        print(\"Processing year:\", year)\n",
    "    \n",
    "        for day in range(len(time)):\n",
    "            ls=[]\n",
    "        \n",
    "            enddate = pd.to_datetime(startdate) + pd.DateOffset(days = day_counter)\n",
    "            enddate = enddate.strftime('%Y-%m-%d') #removing the time stamp from date\n",
    "        \n",
    "            filename = str(enddate)+\".csv\"\n",
    "        \n",
    "            df = pd.read_csv(filename)\n",
    "\n",
    "            row, col = df.shape\n",
    "        \n",
    "            for r in range(row):\n",
    "            \n",
    "                for c in range(col-1):\n",
    "                \n",
    "                    val = df.iloc[r,c+1]\n",
    "                    ls.append(val)\n",
    "            \n",
    "            time_series.loc[i] = ls\n",
    "        \n",
    "            i = i+1 \n",
    "            day_counter = day_counter+1\n",
    "        \n",
    "    time_series.to_csv(\"AET_2005-09.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e9979",
   "metadata": {},
   "outputs": [],
   "source": [
    "compileAET('2005-01-01.csv','D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\AET_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7772ea3",
   "metadata": {},
   "source": [
    "## Step 3: Convert to subbasin level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afce4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert time series data for each location point to subbasin level data - averaged for each subbasin\n",
    "\n",
    "def aettosubbasins(directory,aet,subbasins,dataname):\n",
    "    \n",
    "    os.chdir(directory)\n",
    "    \n",
    "    subbasins = pd.read_excel(subbasins, sheet_name = 'GLEAM_table', engine = 'openpyxl')\n",
    "    aet = pd.read_csv(aet)\n",
    "    \n",
    "    subbasins.sort_values(by='Subbasin', inplace=True)\n",
    "    ls_subsn = subbasins['Subbasin'].unique()\n",
    "    \n",
    "    final_aet = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(ls_subsn)):\n",
    "        \n",
    "        print(\"Processing subbasin number:\", ls_subsn[i])\n",
    "        \n",
    "        sb_df = subbasins[subbasins['Subbasin']==ls_subsn[i]]\n",
    "        ls_loc = sb_df['Location']\n",
    "    \n",
    "        aet_subset = aet[aet['Location'].isin(ls_loc)]\n",
    "        aet_df = pd.merge(aet_subset, sb_df, on = 'Location')\n",
    "        aet_df.drop(['OBJECTID', 'Latitude', 'Longitude', 'Subbasin', 'gridcode','Shape_Area'], axis= 1, inplace = True) \n",
    "        aet_df = aet_df.iloc[:,1:]\n",
    "        aet_df.to_csv('aet_subbasin.csv')\n",
    "        \n",
    "        sum_area = aet_df['Cell_Area'].sum() #calculating the total area under the current subbasin\n",
    "        \n",
    "        temp_xlen = len(aet_df.columns)-1 #determining the number of columns in the dataframe\n",
    "        \n",
    "        ls_aet = []\n",
    "    \n",
    "        for j in range(temp_xlen):\n",
    "            aet_df.iloc[:,j] = aet_df.iloc[:,j] * aet_df['Cell_Area']\n",
    "            avg = aet_df.iloc[:,j].sum()/sum_area #calculating weighted average for each day of the time series\n",
    "            ls_aet.append(avg)\n",
    "    \n",
    "        final_aet[i] = ls_aet\n",
    "    \n",
    "    final_aet.to_csv(dataname + '_aet_subbasins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783872d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aettosubbasins('D:\\TUM\\Master_Thesis\\Benin\\Data\\GLEAM\\GLEAM_AET_processed', 'AET_2005-09.csv',\n",
    "               'GLEAM_subbasins.xlsx', 'GLEAM_AET')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "mtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
