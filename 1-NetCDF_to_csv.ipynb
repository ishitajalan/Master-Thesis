{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ee9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Author: Ishita Jalan ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de8f8a4",
   "metadata": {},
   "source": [
    "## PGF Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Processing Max Temperature Data #########################\n",
    "\n",
    "# Raw data format: netcdf files available for each year\n",
    "\n",
    "os.chdir(\"D:\\TUM\\Master_Thesis\\Benin\\Data\\PGF v3\\Processed_max\")\n",
    "\n",
    "latbounds = [6.125,12.500]\n",
    "lonbounds = [0.675, 4.300]\n",
    "time_interval = 1440\n",
    "\n",
    "for year in range(1998,2013):\n",
    "    filepath = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\PGF v3\\tmax_daily_'+str(year)+'-'+str(year)+'.nc'\n",
    "    ds = nc.Dataset(filepath)\n",
    "    print(\"Processing Year\", year)\n",
    "\n",
    "    day_counter = 0 # Time format in netcdf starts from 3653 for 1990\n",
    "    lat = ds.variables['lat'][:] \n",
    "    lon = ds.variables['lon'][:]\n",
    "    tmax = ds.variables['tmax']\n",
    "    time = ds.variables['time'][:]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "    \n",
    "    startdate = \"01-01-\"+str(year)\n",
    "    \n",
    "    day_counter = 0\n",
    "    \n",
    "    for day in range(len(time)):\n",
    "        enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=day_counter)\n",
    "        #print (\"Processing Date\", enddate)\n",
    "        \n",
    "        TempSubset = ds.variables['tmax'][day, latli:latui ,lonli:lonui ]\n",
    "        temp = np.matrix(TempSubset)\n",
    "        \n",
    "        df = pd.DataFrame(data=temp, columns=(lon[lonli:lonui]), index=(lat[latli:latui]))\n",
    "        day_counter = day_counter+1\n",
    "  \n",
    "        # end date timesstamp to string     \n",
    "        file_date_refined = enddate.strftime('%Y-%m-%d')\n",
    "        df.to_csv(file_date_refined + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Processing Min Temperature Data #########################\n",
    "\n",
    "os.chdir(\"D:\\TUM\\Master_Thesis\\Benin\\Data\\PGF v3\\Processed_min\")\n",
    "\n",
    "latbounds = [6.125,12.500]\n",
    "lonbounds = [0.675, 4.300]\n",
    "time_interval = 1440\n",
    "\n",
    "for year in range(1998,2013):\n",
    "    filepath = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\PGF v3\\tmin_daily_'+str(year)+'-'+str(year)+'.nc'\n",
    "    ds = nc.Dataset(filepath)\n",
    "    print(\"Processing Year\", year)\n",
    "\n",
    "    day_counter = 0 # Time format in netcdf starts from 3653 for 1990\n",
    "    \n",
    "    lat = ds.variables['lat'][:] \n",
    "    lon = ds.variables['lon'][:]\n",
    "    tmin = ds.variables['tmin']\n",
    "    time = ds.variables['time'][:]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "    \n",
    "    startdate = \"01-01-\"+str(year)\n",
    "    \n",
    "    for day in range(len(time)):\n",
    "        enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=day_counter)\n",
    "        #print (\"Processing Date\", enddate)\n",
    "        \n",
    "        TempSubset = ds.variables['tmin'][day, latli:latui ,lonli:lonui ]\n",
    "        temp = np.matrix(TempSubset)\n",
    "        \n",
    "        df = pd.DataFrame(data=temp, columns=(lon[lonli:lonui]), index=(lat[latli:latui]))\n",
    "        day_counter = day_counter+1\n",
    "  \n",
    "        # end date timesstamp to string     \n",
    "        file_date_refined = enddate.strftime('%Y-%m-%d')\n",
    "        df.to_csv(file_date_refined + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e75105",
   "metadata": {},
   "source": [
    "## CPC Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622241b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Processing Max Temperature Data #######################################\n",
    "\n",
    "# Raw data format: netcdf files available for each year\n",
    "\n",
    "os.chdir(r\"D:\\TUM\\Master_Thesis\\Benin\\Data\\CPC\\tmax_csv\")\n",
    "\n",
    "latbounds = [6.125,12.500]\n",
    "lonbounds = [0.675, 4.300]\n",
    "time_interval = 1440\n",
    "\n",
    "for year in range(1998,2013):\n",
    "    filepath = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\CPC\\tmax.' + str(year) + '.nc'\n",
    "    ds = nc.Dataset(filepath)\n",
    "    print(\"Processing Year\", year)\n",
    "\n",
    "    day_counter = 0 \n",
    "    lat = ds.variables['lat'][:] \n",
    "    lon = ds.variables['lon'][:]\n",
    "    tas = ds.variables['tmax']\n",
    "    time = ds.variables['time'][:]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "    \n",
    "    startdate = \"01-01-\"+str(year)\n",
    "    \n",
    "    day_counter = 0\n",
    "    \n",
    "    for day in range(len(time)):\n",
    "        enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=day_counter)\n",
    "        #print (\"Processing Date\", enddate)\n",
    "        \n",
    "        TempSubset = ds.variables['tmax'][day, latui:latli ,lonli:lonui ] #latui is placed before latli here\n",
    "        temp = np.matrix(TempSubset)\n",
    "        \n",
    "        df = pd.DataFrame(data=temp, columns=(lon[lonli:lonui]), index=(lat[latui:latli]))\n",
    "        day_counter = day_counter+1\n",
    "  \n",
    "        # end date timesstamp to string     \n",
    "        file_date_refined = enddate.strftime('%Y-%m-%d')\n",
    "        df.to_csv(file_date_refined + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ed3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Processing Min Temperature Data #######################################\n",
    "\n",
    "os.chdir(r\"D:\\TUM\\Master_Thesis\\Benin\\Data\\CPC\\tmin_csv\")\n",
    "\n",
    "latbounds = [6.125,12.500]\n",
    "lonbounds = [0.675, 4.300]\n",
    "time_interval = 1440\n",
    "\n",
    "for year in range(1998,2013):\n",
    "    filepath = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\CPC\\tmin.' + str(year) + '.nc'\n",
    "    ds = nc.Dataset(filepath)\n",
    "    print(\"Processing Year\", year)\n",
    "\n",
    "    day_counter = 0 \n",
    "    lat = ds.variables['lat'][:] \n",
    "    lon = ds.variables['lon'][:]\n",
    "    tas = ds.variables['tmin']\n",
    "    time = ds.variables['time'][:]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "    \n",
    "    startdate = \"01-01-\"+str(year)\n",
    "    \n",
    "    day_counter = 0\n",
    "    \n",
    "    for day in range(len(time)):\n",
    "        enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=day_counter)\n",
    "        #print (\"Processing Date\", enddate)\n",
    "        \n",
    "        TempSubset = ds.variables['tmin'][day, latui:latli ,lonli:lonui ]\n",
    "        temp = np.matrix(TempSubset)\n",
    "        \n",
    "        df = pd.DataFrame(data=temp, columns=(lon[lonli:lonui]), index=(lat[latui:latli]))\n",
    "        day_counter = day_counter+1\n",
    "  \n",
    "        # end date timesstamp to string     \n",
    "        file_date_refined = enddate.strftime('%Y-%m-%d')\n",
    "        df.to_csv(file_date_refined + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b0c91",
   "metadata": {},
   "source": [
    "## ERA-5 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing ERA-5 dataset\n",
    "\n",
    "#Reading the 4 dataset links to Python workspace\n",
    "\n",
    "file1 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\ERA5\\Download_2\\adaptor.mars.internal-1640886185.6908786-18951-14-c682c7b3-2213-48af-9908-0a473ae4948d.nc'\n",
    "\n",
    "file2 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\ERA5\\Download_2\\adaptor.mars.internal-1640886182.2155783-32385-2-39606770-3c8e-46ce-af4a-dc219fe21c4f.nc'\n",
    "\n",
    "file3 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\ERA5\\Download_2\\adaptor.mars.internal-1640886501.4589589-15293-9-98e87326-72cc-45ed-8530-45366f88e6e9.nc'\n",
    "\n",
    "file4 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\ERA5\\Download_2\\adaptor.mars.internal-1640885829.182744-28165-8-0a5f069d-9ef6-4e24-930b-878960c0e151.nc'\n",
    "\n",
    "ds1 = nc.Dataset(file1) #data from 1998-2001\n",
    "ds2 = nc.Dataset(file2) #data from 2002-2005\n",
    "ds3 = nc.Dataset(file3) #data from 2006-2009\n",
    "ds4 = nc.Dataset(file4) #data from 2010-2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective of the function: Create csv files for each day by first reading hourly data and selecting the max and min \n",
    "#from the set of 24 values in a day\n",
    "\n",
    "os.chdir(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\ERA5\\csv_files')\n",
    "\n",
    "def ERA5read(ds,years,startdate):\n",
    "    time = ds.variables['time'][:]\n",
    "    hour_counter = 0\n",
    "    latbounds = [6.125,12.500]\n",
    "    lonbounds = [0.675, 4.300]\n",
    "    \n",
    "    lat = ds.variables['latitude'][:] \n",
    "    lon = ds.variables['longitude'][:]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "                 \n",
    "    for day in range(int(len(time)/24)):\n",
    "        i=0\n",
    "        enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=day)\n",
    "        #print(\"Processing Date\", enddate)\n",
    "        \n",
    "        array_mx = np.zeros((26,15))\n",
    "        array_mn = np.zeros((26,15))\n",
    "        \n",
    "        ls_max = []\n",
    "        ls_min = []\n",
    "                \n",
    "        for i in range(24):\n",
    "            array_mx = ds.variables['mx2t'][hour_counter+i,latui:latli,lonli:lonui]\n",
    "            array_mn = ds.variables['mn2t'][hour_counter+i,latui:latli,lonli:lonui]\n",
    "            ls_max.append(array_mx)\n",
    "            ls_min.append(array_mn)\n",
    "            i = i+1\n",
    "            \n",
    "        d3_max = array(ls_max)\n",
    "        d3_min = array(ls_min)\n",
    "        day_tmax1 = np.amax(d3_max, axis = 0)\n",
    "        day_tmin1 = np.amin(d3_min, axis = 0)\n",
    "        \n",
    "        hour_counter = hour_counter + 24\n",
    "        \n",
    "        day_tmax = np.matrix(day_tmax1)\n",
    "        day_tmin = np.matrix(day_tmin1)\n",
    "    \n",
    "        df_max = pd.DataFrame(data = day_tmax, columns=(lon[lonli:lonui]), index=(lat[latui:latli]))\n",
    "        df_min = pd.DataFrame(data = day_tmin, columns=(lon[lonli:lonui]), index=(lat[latui:latli]))\n",
    "  \n",
    "        # end date timesstamp to string     \n",
    "        file_date_max = enddate.strftime('%Y-%m-%d') + \"_max\"\n",
    "        file_date_min = enddate.strftime('%Y-%m-%d') + \"_min\"\n",
    "            \n",
    "        df_max.to_csv(file_date_max + '.csv')\n",
    "        df_min.to_csv(file_date_min + '.csv')\n",
    "        \n",
    "        print(\"Processed Day:\", day)\n",
    "        day = day + 1\n",
    "        \n",
    "    return(day,hour_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day, hour_counter = ERA5read(ds1, 4, '01-01-1998')\n",
    "day, hour_counter = ERA5read(ds2, 4, '01-01-2002')\n",
    "day, hour_counter = ERA5read(ds3, 4, '01-01-2006')\n",
    "day, hour_counter = ERA5read(ds4, 3, '01-01-2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9e676",
   "metadata": {},
   "source": [
    "## EWEMBI Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506132bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prcoessing EWEMBI dataset\n",
    "\n",
    "#EWEMBI files were downloaded into three parts for minimum temperature and maximum temperature\n",
    "\n",
    "# Minimum Temperature files\n",
    "file1 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\Temp_preprocess\\EWEMBI_v1.1-second_download\\tas_min_1990_2020\\tasmin_ewembi_1991_2000_lat6.125to12.043lon0.675to4.123.nc4'\n",
    "file2 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\Temp_preprocess\\EWEMBI_v1.1-second_download\\tas_min_1990_2020\\EWEMBI_v1.1-second_download\\tas_min_1990_2020\\tasmin_ewembi_2001_2010_lat6.125to12.043lon0.675to4.123.nc4'\n",
    "file3 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\Temp_preprocess\\EWEMBI_v1.1-second_download\\tas_min_1990_2020\\EWEMBI_v1.1-second_download\\tas_min_1990_2020\\tasmin_ewembi_2011_2016_lat6.125to12.043lon0.675to4.123.nc4'\n",
    "\n",
    "ds1 = nc.Dataset(file1)\n",
    "ds2 = nc.Dataset(file2)\n",
    "ds3 = nc.Dataset(file3)\n",
    "\n",
    "#Maximum Temperature files\n",
    "file4 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\Temp_preprocess\\EWEMBI_v1.1-second_download\\tas_max_1990_2020\\EWEMBI_v1.1-second_download\\tas_max_1990_2020\\tasmax_ewembi_1991_2000_lat6.125to12.043lon0.675to4.123.nc4'\n",
    "file5 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\Temp_preprocess\\EWEMBI_v1.1-second_download\\tas_max_1990_2020\\EWEMBI_v1.1-second_download\\tas_max_1990_2020\\tasmax_ewembi_2001_2010_lat6.125to12.043lon0.675to4.123.nc4'\n",
    "file6 = r'D:\\TUM\\Master_Thesis\\Benin\\Data\\Temp_preprocess\\EWEMBI_v1.1-second_download\\tas_max_1990_2020\\EWEMBI_v1.1-second_download\\tas_max_1990_2020\\tasmax_ewembi_2011_2016_lat6.125to12.043lon0.675to4.123.nc4'\n",
    "\n",
    "ds4 = nc.Dataset(file4)\n",
    "ds5 = nc.Dataset(file5)\n",
    "ds6 = nc.Dataset(file6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to convert EWEMBI data in netcdf format to csv files \n",
    "\n",
    "os.chdir(r'D:\\TUM\\Master_Thesis\\Benin\\Data\\EWEMBI_v1.1-second_download\\csv_files')\n",
    "\n",
    "def EWEMBIread(ds_max, ds_min, daycount_start, day_count, startdate):\n",
    "    \n",
    "    time_max = ds_max.variables['time'][:]\n",
    "    time_min = ds_min.variables['time'][:]\n",
    "    \n",
    "    lat = ds_max.variables['lat'][:] \n",
    "    lon = ds_max.variables['lon'][:]\n",
    "    \n",
    "    latbounds = [6.125,12.500]\n",
    "    lonbounds = [0.675, 4.300]\n",
    "    \n",
    "    # latitude lower and upper index\n",
    "    latli = np.argmin( np.abs( lat - latbounds[0] ) )\n",
    "    latui = np.argmin( np.abs( lat - latbounds[1] ) ) \n",
    "            \n",
    "    # longitude lower and upper index\n",
    "    lonli = np.argmin( np.abs( lon - lonbounds[0] ) )\n",
    "    lonui = np.argmin( np.abs( lon - lonbounds[1] ) )\n",
    "    \n",
    "    if(len(time_max)==len(time_min)):\n",
    "        \n",
    "        for day in range(day_count):\n",
    "            enddate = pd.to_datetime(startdate)+ pd.DateOffset(days=daycount_start)\n",
    "            print(\"Processing Date\", enddate)\n",
    "        \n",
    "            tmax = ds_max.variables['tasmax'][daycount_start,latui:latli, lonli:lonui]\n",
    "            tmin = ds_min.variables['tasmin'][daycount_start,latui:latli, lonli:lonui]\n",
    "        \n",
    "            temp_max = np.matrix(tmax)\n",
    "            temp_min = np.matrix(tmin)\n",
    "                        \n",
    "            df_max = pd.DataFrame(data = temp_max, columns=(lon[lonli:lonui]), index=(lat[latui:latli]))\n",
    "            df_min = pd.DataFrame(data = temp_min, columns=(lon[lonli:lonui]), index=(lat[latui:latli]))\n",
    "  \n",
    "            # end date timesstamp to string     \n",
    "            file_date_max = enddate.strftime('%Y-%m-%d') + \"_max\"\n",
    "            file_date_min = enddate.strftime('%Y-%m-%d') + \"_min\"\n",
    "            \n",
    "            df_max.to_csv(file_date_max + '.csv')\n",
    "            df_min.to_csv(file_date_min + '.csv')\n",
    "            \n",
    "            daycount_start = daycount_start + 1 \n",
    "            \n",
    "        return (day_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff13161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing files ds4 and ds1\n",
    "\n",
    "# counting the number of days between two dates\n",
    "\n",
    "day1 = date(1991,1,1)\n",
    "day2 = date(1998,1,1)\n",
    "daycount_start = day2 - day1 #defining the start day count\n",
    "\n",
    "day3 = date(1998,1,1)\n",
    "day4 = date(2000,12,31)\n",
    "days = day4 - day3 #defining the number of days to be processed\n",
    "\n",
    "day_count = EWEMBIread(ds4, ds1, daycount_start.days, days.days+1, '01-01-1991')\n",
    "\n",
    "# Processing files ds5 and ds2\n",
    "\n",
    "# counting the number of days between two dates\n",
    "\n",
    "day3 = date(2001,1,1)\n",
    "day4 = date(2010,12,31)\n",
    "days = day4 - day3 #defining the number of days to be processed\n",
    "\n",
    "day_count = EWEMBIread(ds5, ds2, 0, days.days+1, '01-01-2001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv",
   "language": "python",
   "name": "mtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
